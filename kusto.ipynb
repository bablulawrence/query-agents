{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query Agent Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "from logging import StreamHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "  \n",
    "# Configure environment variables  \n",
    "az_search_service_endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "az_search_index_name = os.environ[\"AZURE_SEARCH_INDEX_NAME\"]\n",
    "az_search_credential = AzureKeyCredential(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = os.environ['OPENAI_API_TYPE']\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.api_base = os.environ[\"OPENAI_API_BASE\"]\n",
    "openai.api_version = os.environ[\"OPENAI_API_VERSION\"]\n",
    "text_gen_deploy_name = os.environ[\"OPENAI_API_TEXT_GEN_DEPLOY\"]\n",
    "embeddings_deploy_name = os.environ[\"OPENAI_API_EMBEDDINGS_DEPLOY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_gen_deploy_name)\n",
    "print(az_search_index_name)\n",
    "print(az_search_service_endpoint)\n",
    "print(az_search_credential)\n",
    "print(embeddings_deploy_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_queries = [\n",
    "    \"Who are my most valuable customers\",                               #0\n",
    "    \"Give me 10 products\",                                              #1\n",
    "    \"Which products are sold most in NY and PA\",                        #2\n",
    "    \"Which products are sold most in Newyork and Pennsylvania\",         #3\n",
    "    \"I need top selling products\",                                      #4\n",
    "    \"How many customers are there in NY\",                               #5\n",
    "    \"How many customers are there in Utah\",                             #6\n",
    "    \"How many customers are there in UT\"                                #7\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = nl_queries[0]\n",
    "search_client = SearchClient(az_search_service_endpoint, \n",
    "                             az_search_index_name, \n",
    "                             credential=az_search_credential)  \n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def generate_embeddings(text):\n",
    "    response = openai.Embedding.create(input=text, engine=embeddings_deploy_name)\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector=generate_embeddings(query),\n",
    "    top_k=3,  \n",
    "    vector_fields=\"NLQueryVector\",\n",
    "    select=[\"NLQuery\", \"KQLQuery\"],\n",
    ")  \n",
    "\n",
    "results = [{ \n",
    "                \"NLQuery\": result[\"NLQuery\"], \n",
    "                \"KQLQuery\": result[\"KQLQuery\"]\n",
    "            } for result in list(results)]\n",
    "# print(json.dumps(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/kql_reference.json\", 'r') as language_ref_file, \\\n",
    "     open(\"./data/database_schema.json\", 'r') as db_schema_file, \\\n",
    "     open(\"./data/kql_examples.json\", 'r') as examples_file:\n",
    "    language_reference = language_ref_file.read().strip()\n",
    "    database_schema = db_schema_file.read().strip()\n",
    "#     translation_examples = examples_file.read().strip()\n",
    "    translation_examples = json.dumps(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(database_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_examples=f\"\"\"\n",
    "Give me the total number of products\n",
    "Thought: I need to count all rows from products table.\n",
    "OutputQuery:\n",
    "products\n",
    "| count\n",
    "WAITING\n",
    "\n",
    "You will be then called again with the results of query execution:\n",
    "Results:\n",
    "77\n",
    "\n",
    "You will then output the following:\n",
    "Thought: Query is returning rows, there are no errors apparently. Therefore it is correct. \n",
    "OutputQuery:\n",
    "products\n",
    "| count\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter='####'\n",
    "prompt=f\"\"\"As an expert in Kusto Query Language, your task is to translate natural language queries into KQL queries.\n",
    "The process will proceed through a series of steps in a loop until an accurate query is obtained.\n",
    "\n",
    "To accomplish this task, you will utilize:\n",
    "\n",
    "1. Sample Translations: This helps to understand how input query can be translated into KQL for the specific database your are querying: \n",
    "{translation_examples}\n",
    "2. Database Schema Reference: This helps to determine the tables and columns that need to be used in the output query: \n",
    "{database_schema}\n",
    "3. Language Reference: This helps to understand the syntax of the output query: \n",
    "{language_reference}\n",
    "\n",
    "You will output the steps using the following format:\n",
    "\n",
    "Thought:  You will describe your thought process on how to translate the input query into KQL.\n",
    "OutputQuery:  You will generate the output query.\n",
    "WAITING:  You will return WAITING.\n",
    "\n",
    "Results: This is the result of the query execution(first few rows only) which will be provided to you in the next call;\\\n",
    "You will not generate this yourself.\n",
    "\n",
    "You will analyze the results for errors and inaccuracies, if it is correct, you will generate final output in the following format:\n",
    "Thought: Your thought process about the results. \n",
    "FinalQuery: the latest output query generated. You will not include Results or OutputQuery in the final output.\n",
    "\n",
    "Here are some example sessions: \n",
    "{session_examples}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.kusto.data import KustoClient, KustoConnectionStringBuilder\n",
    "from azure.kusto.data.exceptions import KustoServiceError\n",
    "from azure.kusto.data.helpers import dataframe_from_result_table\n",
    "import pandas as pd\n",
    "\n",
    "class KQLTools:\n",
    "    def __init__(self, cluster, database) -> None:\n",
    "        aad_tenant_id = os.environ['AAD_TENANT_ID']\n",
    "        aad_client_id = os.environ['AAD_CLIENT_ID']\n",
    "        aad_client_secret = os.environ['AAD_CLIENT_SECRET']\n",
    "        kscb = KustoConnectionStringBuilder.with_aad_application_key_authentication(cluster, \n",
    "                                                    aad_client_id,\n",
    "                                                    aad_client_secret, \n",
    "                                                    aad_tenant_id)\n",
    "        self.client = KustoClient(kscb)\n",
    "        self.database = database\n",
    "\n",
    "    def execute_query(self, query):\n",
    "        response  = self.client.execute(self.database, query)\n",
    "        result_df = dataframe_from_result_table(response.primary_results[0])\n",
    "        return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LLMChat:\n",
    "    def __init__(self, system_prompt=\"\", debug=False):\n",
    "        self.messages = []\n",
    "        self.debug = False\n",
    "        self.messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    \n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.run()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "    \n",
    "    def run(self, debug=False):        \n",
    "        completion = openai.ChatCompletion.create(engine=text_gen_deploy_name, \n",
    "                                                  temperature=0,\n",
    "                                                  messages=self.messages)\n",
    "        if (self.debug):\n",
    "            {\"completion_tokens\": 86, \"prompt_tokens\": 26, \"total_tokens\": 112}\n",
    "            print(completion.usage)        \n",
    "        return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(debug=False):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.DEBUG if debug else logging.INFO)\n",
    "\n",
    "    # Remove all handlers associated with the logger object by default.\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)\n",
    "\n",
    "    # Create a console handler\n",
    "    ch = logging.StreamHandler(sys.stdout)\n",
    "    ch.setLevel(logging.DEBUG if debug else logging.INFO)\n",
    "\n",
    "    # Create formatter and add it to the handlers\n",
    "    formatter = logging.Formatter('%(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "\n",
    "    # Add the handlers to the logger\n",
    "    logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryAgent(LLMChat):\n",
    "    def __init__(self, system_prompt, db_tools, max_tries=5, debug=False):\n",
    "        super().__init__(system_prompt, debug)        \n",
    "        self.max_tries = max_tries\n",
    "        self.db_tools = db_tools\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    # def extract_query(self, result):\n",
    "    #     return [self.query_re.match(a) for a in result.split('\\n') if self.query_re.match(a)]\n",
    "\n",
    "    def extract_query(self, text):\n",
    "        pattern_final = re.compile(r'FinalQuery:(.*?)(?:(?=\\nOutputQuery:)|(?=$))', re.DOTALL)\n",
    "        matches_final = pattern_final.findall(text)\n",
    "        \n",
    "        if matches_final:\n",
    "            return 'Final', matches_final[0].strip()\n",
    "        \n",
    "        pattern_output = re.compile(r'OutputQuery:(.*?)(?:(?=\\nWAITING)|(?=\\nOutputQuery:)|(?=$))', re.DOTALL)\n",
    "        matches_output = pattern_output.findall(text)\n",
    "\n",
    "        return 'Output', matches_output[-1].strip() if matches_output else None    \n",
    "    \n",
    "\n",
    "    def query(self, input_query, sample_rows_num=5):\n",
    "        next_prompt = input_query\n",
    "        self.logger.info(next_prompt)\n",
    "        for i in range(self.max_tries):\n",
    "            llm_result = super().__call__(next_prompt)\n",
    "            self.logger.info(llm_result)\n",
    "            query_type, query_text = self.extract_query(llm_result)\n",
    "            if query_type == 'Output':\n",
    "                # print(\"kql\\n\" + query_text)\n",
    "                try: \n",
    "                    query_results=self.db_tools.execute_query(query_text)\n",
    "                    next_prompt = f\"Results: {query_results.head(sample_rows_num).to_csv()}\"\n",
    "                except Exception as e:\n",
    "                    next_prompt = f\"Results: {e}\"\n",
    "                # self.logger.info(next_prompt)\n",
    "            else:\n",
    "                return query_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging(debug=True)\n",
    "kusto_cluster = \"https://dxp01.adnocpocsynapse.kusto.azuresynapse.net\"\n",
    "kusto_database = \"retail_org\"\n",
    "kql_tools = KQLTools(kusto_cluster, kusto_database)\n",
    "\n",
    "kql_agent = QueryAgent(prompt,kql_tools, max_tries=3, debug=True)\n",
    "kql_query=kql_agent.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kql_query)\n",
    "print(kql_tools.execute_query(kql_query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
